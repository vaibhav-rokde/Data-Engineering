{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NyMxF-ETy1UA"
      },
      "outputs": [],
      "source": [
        "#Import the necessary modules\n",
        "from pyspark.sql import SparkSession\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaTLuRSmzmZh",
        "outputId": "36e278fe-5a1e-4a64-a8e3-69af8159c558"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=c2dfd5dec52ae9e2f7b0545ee8acb9914ec77856c1d77bd5224b8c7a5de90054\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CSV and Excel Reader\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "fUFHeIs00WWH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_path = \"/content/titanic_test.csv\"\n",
        "csv_df = spark.read.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .load(csv_file_path)\n",
        "csv_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDfpW6wQ0cmD",
        "outputId": "eda8c12b-bafe-4b22-9a6c-df53cbb62273"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
            "|passenger_id|pclass|                name|   sex|   age|sibsp|parch|          ticket|    fare|cabin|embarked|boat| body|           home.dest|\n",
            "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
            "|         295|     1|Thayer, Mr. John ...|  male|  17.0|    0|    2|           17421|110.8833|  C70|       C|   B| null|       Haverford, PA|\n",
            "|        1150|     3|Risien, Mr. Samue...|  male|  null|    0|    0|          364498|    14.5| null|       S|null| null|                null|\n",
            "|          89|     1|Davidson, Mr. Tho...|  male|  31.0|    1|    0|      F.C. 12750|    52.0|  B71|       S|null| null|        Montreal, PQ|\n",
            "|        1063|     3|Nirva, Mr. Iisakk...|  male|  41.0|    0|    0|SOTON/O2 3101272|   7.125| null|       S|null| null| Finland Sudbury, ON|\n",
            "|        1020|     3|  Minkoff, Mr. Lazar|  male|  21.0|    0|    0|          349211|  7.8958| null|       S|null| null|                null|\n",
            "|         747|     3|Danbom, Master. G...|  male|0.3333|    0|    2|          347080|    14.4| null|       S|null| null|         Stanton, IA|\n",
            "|         368|     2|Chapman, Mr. John...|  male|  37.0|    1|    0|     SC/AH 29037|    26.0| null|       S|null| 17.0|Cornwall / Spokan...|\n",
            "|        1047|     3|\"Najib, Miss. Ade...|female|  15.0|    0|    0|            2667|   7.225| null|       C|   C| null|                null|\n",
            "|         569|     2|Sweet, Mr. George...|  male|  14.0|    0|    0|          220845|    65.0| null|       S|null| null|Somerset / Bernar...|\n",
            "|         232|     1|Porter, Mr. Walte...|  male|  47.0|    0|    0|          110465|    52.0| C110|       S|null|207.0|       Worcester, MA|\n",
            "|         365|     2|Carter, Mrs. Erne...|female|  44.0|    1|    0|          244252|    26.0| null|       S|null| null|              London|\n",
            "|         351|     2|Brown, Mr. Thomas...|  male|  60.0|    1|    1|           29750|    39.0| null|       S|null| null|Cape Town, South ...|\n",
            "|         535|     2|Phillips, Mr. Esc...|  male|  43.0|    0|    1|     S.O./P.P. 2|    21.0| null|       S|null| null|   Ilfracombe, Devon|\n",
            "|         287|     1|Sutton, Mr. Frede...|  male|  61.0|    0|    0|           36963| 32.3208|  D50|       S|null| 46.0|     Haddenfield, NJ|\n",
            "|         767|     3|Demetri, Mr. Marinko|  male|  null|    0|    0|          349238|  7.8958| null|       S|null| null|                null|\n",
            "|         528|     2|\"Parkes, Mr. Fran...|  male|  null|    0|    0|          239853|     0.0| null|       S|null| null|             Belfast|\n",
            "|         430|     2|\"Harper, Miss. An...|female|   6.0|    0|    1|          248727|    33.0| null|       S|  11| null|Denmark Hill, Sur...|\n",
            "|          60|     1|Cavendish, Mr. Ty...|  male|  36.0|    1|    0|           19877|   78.85|  C46|       S|null|172.0|Little Onn Hall, ...|\n",
            "|        1212|     3|Slabenoff, Mr. Petco|  male|  null|    0|    0|          349214|  7.8958| null|       S|null| null|                null|\n",
            "|         462|     2|Jefferys, Mr. Cli...|  male|  24.0|    2|    0|      C.A. 31029|    31.5| null|       S|null| null|Guernsey / Elizab...|\n",
            "+------------+------+--------------------+------+------+-----+-----+----------------+--------+-----+--------+----+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_output_path = \"/content/titanic.csv\"\n",
        "csv_df.write.format(\"csv\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .save(csv_output_path)\n",
        "print(\"saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUeAb9mo2Ilu",
        "outputId": "4b21131d-ea43-4707-bc6d-6c6dac5145a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To perform CRUD \n",
        "(Create, Read, Update, Delete) operations in a SQL Server database using PySpark, you can utilize the JDBC API provided by PySpark. Here's an overview of how you can execute each of the CRUD operations:"
      ],
      "metadata": {
        "id": "aCKHKb1g2h9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "ck0O30Ci2mgX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"SQL Server CRUD\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "LvrH3tWa2pq_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jdbc_url = \"jdbc:sqlserver://<server_name>:<port>;databaseName=<database_name>\"\n",
        "connection_properties = {\n",
        "    \"user\": \"<username>\",\n",
        "    \"password\": \"<password>\",\n",
        "    \"driver\": \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "fMqva0Vo2vo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create (INSERT) operation:"
      ],
      "metadata": {
        "id": "x5u7sfmf21m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the data to be inserted\n",
        "data = [(\"John\", 25), (\"Alice\", 30)]\n",
        "columns = [\"name\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Write the DataFrame to the SQL Server table\n",
        "table_name = \"your_table_name\"\n",
        "df.write.jdbc(url=jdbc_url,\n",
        "              table=table_name,\n",
        "              mode=\"append\",\n",
        "              properties=connection_properties)\n"
      ],
      "metadata": {
        "id": "NfrBUX-O2wrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read (SELECT) operation"
      ],
      "metadata": {
        "id": "l0wDX8O5256g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from the SQL Server table\n",
        "table_name = \"your_table_name\"\n",
        "df = spark.read.jdbc(url=jdbc_url,\n",
        "                     table=table_name,\n",
        "                     properties=connection_properties)\n",
        "\n",
        "# Perform operations on the DataFrame\n",
        "df.show()\n"
      ],
      "metadata": {
        "id": "YYA5OP1Q29-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update (UPDATE) operation:\n"
      ],
      "metadata": {
        "id": "l43fr--S3DbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the update operation\n",
        "table_name = \"your_table_name\"\n",
        "condition = \"age > 30\"\n",
        "new_age = 40\n",
        "df.where(condition).withColumn(\"age\", new_age).write.jdbc(url=jdbc_url,\n",
        "                                                           table=table_name,\n",
        "                                                           mode=\"overwrite\",\n",
        "                                                           properties=connection_properties)\n"
      ],
      "metadata": {
        "id": "joPKJptF25kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delete (DELETE) operation"
      ],
      "metadata": {
        "id": "8HtjlvIG3HG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the delete operation\n",
        "table_name = \"your_table_name\"\n",
        "condition = \"name = 'John'\"\n",
        "df.where(condition).write.jdbc(url=jdbc_url,\n",
        "                               table=table_name,\n",
        "                               mode=\"delete\",\n",
        "                               properties=connection_properties)\n"
      ],
      "metadata": {
        "id": "MM_prgo93G7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}