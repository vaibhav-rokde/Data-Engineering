{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAjaDVFIGctDp4B5wBSQkg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#!pip install pyspark"],"metadata":{"id":"nGx_FWRglEyl","executionInfo":{"status":"ok","timestamp":1686054889197,"user_tz":-330,"elapsed":645,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":["Resilient Distributed Datasets (RDD) is a fundamental data structure in Apache Spark, which is a fast and distributed processing engine for big data analytics. RDDs provide a fault-tolerant and distributed way of processing and manipulating data in parallel across a cluster of machines.\n","\n","Here's an overview of RDDs in PySpark:\n","\n","**Creation of RDDs:** \n","  RDDs can be created in PySpark from various data sources such as Hadoop Distributed File System (HDFS), local file systems, or by transforming existing RDDs or other data structures. RDDs can be created using the parallelize() method to distribute a collection or by loading data from external sources.\n","\n","**Immutable and Partitioned:** \n","  RDDs are immutable, meaning they cannot be modified once created. Instead, transformations are applied to RDDs to create new RDDs. RDDs are also partitioned, where data is divided into smaller partitions that can be processed in parallel across a cluster.\n","\n","**Resilience and Fault-Tolerance:** \n","  RDDs are designed to be resilient, meaning they can recover from failures. RDDs achieve fault-tolerance by keeping track of the lineage, which is the history of transformations applied to the base data. If a partition is lost due to a failure, Spark can recompute the lost partition using the lineage.\n","\n","**Transformation and Action Operations:** \n","  RDDs support two types of operations: transformations and actions. Transformations are operations that produce new RDDs from existing RDDs, such as map(), filter(), reduceByKey(), etc. Actions are operations that compute a result or return a value, such as count(), collect(), reduce(), etc.\n","\n","**Lazy Evaluation:** \n","  RDDs follow lazy evaluation, which means that transformations on RDDs are not immediately executed. Instead, Spark optimizes the execution plan and waits until an action operation is called to trigger the actual computation. This optimization allows for efficient execution and minimizes unnecessary computation.\n","\n","**Caching:** \n","  RDDs can be cached in memory to improve performance. By caching an RDD, intermediate results can be stored in memory, allowing for faster access and reuse of data across multiple computations. Caching is particularly useful when an RDD is accessed multiple times or when iterative algorithms are applied.\n","\n","  RDDs form the core data structure in PySpark, enabling distributed data processing and computation. They provide a high-level API for working with big data and allow developers to write parallel and scalable data processing code. However, it's worth noting that newer versions of Spark (2.x and above) provide higher-level abstractions like DataFrames and Datasets, which offer optimizations and a more expressive API compared to RDDs."],"metadata":{"id":"yZ-qiAQMXMr-"}},{"cell_type":"markdown","source":["In PySpark, a schema defines the structure and data types of a DataFrame or a structured RDD. It provides a way to organize and describe the data contained within a DataFrame, specifying the column names and their corresponding data types. The schema helps define the structure of the data and allows PySpark to optimize query execution and perform various data operations efficiently.\n","\n","Here's an example of how to define a schema in PySpark using the pyspark.sql.types module:"],"metadata":{"id":"rdg7em3bXiW7"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xlwL-GnW_AP","executionInfo":{"status":"ok","timestamp":1686052908445,"user_tz":-330,"elapsed":4290,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"396a5441-15f9-45dd-b38a-20680baa45d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","| John| 25|New York|\n","|Alice| 30|  London|\n","|  Bob| 35|   Paris|\n","+-----+---+--------+\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Define the schema\n","schema = StructType([\n","    StructField(\"name\", StringType(), nullable=False),\n","    StructField(\"age\", IntegerType(), nullable=True),\n","    StructField(\"city\", StringType(), nullable=True)\n","])\n","\n","# Create a DataFrame with the defined schema\n","data = [(\"John\", 25, \"New York\"), (\"Alice\", 30, \"London\"), (\"Bob\", 35, \"Paris\")]\n","df = spark.createDataFrame(data, schema)\n","\n","# Display the DataFrame\n","df.show()\n"]},{"cell_type":"markdown","source":["In the example above, we define a schema using the StructType class and specify the column names and data types using StructField. In this case, we have three columns: \"name\" (StringType), \"age\" (IntegerType), and \"city\" (StringType). We set the nullable parameter to False for the \"name\" column to indicate that it cannot contain null values.\n","\n","We then create a DataFrame df by providing the data and the defined schema to the createDataFrame() method. Finally, we display the DataFrame using the show() method."],"metadata":{"id":"K9HEkHENkqWE"}},{"cell_type":"markdown","source":["## Lambda Expressions pyspark"],"metadata":{"id":"8bvg7ZuwkwCr"}},{"cell_type":"markdown","source":["Lambda expressions are anonymous functions that are commonly used in programming languages to create small, inline functions. In PySpark, which is the Python library for Apache Spark, lambda expressions can be utilized to define functions on the fly.\n","\n","Lambda expressions in PySpark are typically used in conjunction with higher-order functions such as *map(), filter(), and reduce()* to perform operations on distributed collections of data. These higher-order functions take other functions as arguments, and lambda expressions provide a convenient way to define these functions without explicitly naming them.\n","\n","Here's an example of using a lambda expression with the map() function in PySpark to square each element in an RDD (Resilient Distributed Dataset):"],"metadata":{"id":"sCFGm7WjmOV9"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Create an RDD with some numbers\n","numbers_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n","\n","# Use map() with a lambda expression to square each number\n","squared_rdd = numbers_rdd.map(lambda x: x ** 2)\n","\n","# Collect the results\n","result = squared_rdd.collect()\n","print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_1nl8wKYEAp","executionInfo":{"status":"ok","timestamp":1686053153323,"user_tz":-330,"elapsed":1180,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"b5b98e68-634e-487b-b271-2acc15b5d4cd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 4, 9, 16, 25]\n"]}]},{"cell_type":"markdown","source":["### map() function:\n","  The map() function applies a given function to each element of an RDD and returns a new RDD with the transformed elements. Lambda expressions can be used to define the function to be applied. For example:"],"metadata":{"id":"Jep5pPZsrxgp"}},{"cell_type":"code","source":["numbers_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n","squared_rdd = numbers_rdd.map(lambda x: x ** 2)\n","squared_rdd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eV__sc2r0Uq","executionInfo":{"status":"ok","timestamp":1686054635976,"user_tz":-330,"elapsed":5,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"cbd83314-3359-493b-8cf6-93bac85f8cc2"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[112] at RDD at PythonRDD.scala:53"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["### filter() function:\n","  The filter() function creates a new RDD by selecting the elements that satisfy a given condition. Lambda expressions can be used to define the condition. For example:"],"metadata":{"id":"G-i2ekAZsWYe"}},{"cell_type":"code","source":["numbers_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n","even_rdd = numbers_rdd.filter(lambda x: x % 2 == 0)\n"],"metadata":{"id":"HiWcEOsjsFhs","executionInfo":{"status":"ok","timestamp":1686054767860,"user_tz":-330,"elapsed":437,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["### reduce() function:\n","The reduce() function aggregates the elements of an RDD using a specified binary operator. Lambda expressions can be used to define the binary operator. For example, to find the sum of all elements in an RDD:"],"metadata":{"id":"_UymdSZWsFSe"}},{"cell_type":"code","source":["numbers_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n","sum_of_elements = numbers_rdd.reduce(lambda x, y: x + y)\n"],"metadata":{"id":"u8GPp7WPsDaR","executionInfo":{"status":"ok","timestamp":1686054793564,"user_tz":-330,"elapsed":416,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["### Sorting with sortBy() function:\n","The sortBy() function sorts the elements of an RDD based on a specified key. Lambda expressions can be used to define the key. For example, to sort an RDD of tuples based on the second element:"],"metadata":{"id":"KSJj48lzsn3Q"}},{"cell_type":"code","source":["data_rdd = spark.sparkContext.parallelize([(1, 'a'), (2, 'c'), (3, 'b')])\n","sorted_rdd = data_rdd.sortBy(lambda x: x[1])\n"],"metadata":{"id":"-yKnd0pVsoPf","executionInfo":{"status":"ok","timestamp":1686054832911,"user_tz":-330,"elapsed":1180,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["### Custom transformations:\n","Lambda expressions can be used to define custom transformations on RDDs. For example, to transform an RDD by adding a constant value to each element:"],"metadata":{"id":"8BRlwuCVsC_G"}},{"cell_type":"code","source":["numbers_rdd = spark.sparkContext.parallelize([1, 2, 3, 4, 5])\n","transformed_rdd = numbers_rdd.map(lambda x: x + 10)\n"],"metadata":{"id":"VOFb9qVosxPv","executionInfo":{"status":"ok","timestamp":1686054859550,"user_tz":-330,"elapsed":397,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["## Transformations pyspark"],"metadata":{"id":"5cJ0ZbqEm912"}},{"cell_type":"markdown","source":["In PySpark, transformations are operations that are applied to a DataFrame or an RDD (Resilient Distributed Dataset) to create a new DataFrame or RDD. Transformations are lazy operations, meaning they are not executed immediately but create a directed acyclic graph (DAG) representing the computation. The actual execution is triggered when an action is called on the DataFrame or RDD."],"metadata":{"id":"X7WI0KmQnFRc"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Define the schema\n","schema = StructType([\n","    StructField(\"name\", StringType(), nullable=False),\n","    StructField(\"age\", IntegerType(), nullable=True),\n","    StructField(\"city\", StringType(), nullable=True)\n","])\n","\n","# Create a DataFrame with the defined schema\n","data = [(\"John\", 25, \"New York\"), (\"Alice\", 30, \"London\"), (\"Bob\", 35, \"Paris\")]\n","df = spark.createDataFrame(data, schema)\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWS8hUH1m-pb","executionInfo":{"status":"ok","timestamp":1686053373527,"user_tz":-330,"elapsed":1354,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"ce1e9da4-1f6c-4e42-91bd-4ee7a8b3eff9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","| John| 25|New York|\n","|Alice| 30|  London|\n","|  Bob| 35|   Paris|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df.select(\"name\", \"age\").show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuAugcfZnIlH","executionInfo":{"status":"ok","timestamp":1686053414707,"user_tz":-330,"elapsed":1042,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"f7d8e36b-8856-4a9c-fb74-e8c332006fcc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+\n","| name|age|\n","+-----+---+\n","| John| 25|\n","|Alice| 30|\n","|  Bob| 35|\n","+-----+---+\n","\n"]}]},{"cell_type":"code","source":["df.filter(df.age > 30).show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vl1xYxuonRx3","executionInfo":{"status":"ok","timestamp":1686053449610,"user_tz":-330,"elapsed":949,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"37206c5e-d63a-4968-f29a-49a50107649c"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---+-----+\n","|name|age| city|\n","+----+---+-----+\n","| Bob| 35|Paris|\n","+----+---+-----+\n","\n"]}]},{"cell_type":"code","source":["df.withColumn(\"new_column\", df.name + df.city).show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEnoBXOQneSh","executionInfo":{"status":"ok","timestamp":1686053546787,"user_tz":-330,"elapsed":1158,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"ab0a87f8-90c2-4cb0-b53d-303a899d9970"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+----------+\n","| name|age|    city|new_column|\n","+-----+---+--------+----------+\n","| John| 25|New York|      null|\n","|Alice| 30|  London|      null|\n","|  Bob| 35|   Paris|      null|\n","+-----+---+--------+----------+\n","\n"]}]},{"cell_type":"code","source":["df.groupBy(\"name\").sum(\"age\").show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKh6ry1xntQA","executionInfo":{"status":"ok","timestamp":1686053602677,"user_tz":-330,"elapsed":1229,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"abde8c4b-5675-470a-b6a6-2fd2d1439fce"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------+\n","| name|sum(age)|\n","+-----+--------+\n","| John|      25|\n","|  Bob|      35|\n","|Alice|      30|\n","+-----+--------+\n","\n"]}]},{"cell_type":"code","source":["df.orderBy(\"age\", ascending=False).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUG4-l-CoDtX","executionInfo":{"status":"ok","timestamp":1686053636265,"user_tz":-330,"elapsed":2033,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"50a3039c-56cf-422e-96ec-fbea20d6906d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","|  Bob| 35|   Paris|\n","|Alice| 30|  London|\n","| John| 25|New York|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df.distinct().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMcM4WtyoJFc","executionInfo":{"status":"ok","timestamp":1686053665654,"user_tz":-330,"elapsed":749,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"e21ebff7-557b-46d9-9469-09deacfe331f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","| John| 25|New York|\n","|  Bob| 35|   Paris|\n","|Alice| 30|  London|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["# Define the schema\n","schema = StructType([\n","    StructField(\"name\", StringType(), nullable=False),\n","    StructField(\"age\", IntegerType(), nullable=True),\n","    StructField(\"city\", StringType(), nullable=True)\n","])\n","\n","# Create a DataFrame with the defined schema\n","data1 = [(\"k\", 25, \"New York\"), (\"A\", 30, \"London\"), (\"B\", 35, \"Paris\")]\n","df1 = spark.createDataFrame(data1, schema)\n","df1.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-L1HhJr7oQq7","executionInfo":{"status":"ok","timestamp":1686053738050,"user_tz":-330,"elapsed":1130,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"a49aad15-e96a-4266-c2e5-307887a7bf99"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---+--------+\n","|name|age|    city|\n","+----+---+--------+\n","|   k| 25|New York|\n","|   A| 30|  London|\n","|   B| 35|   Paris|\n","+----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df1.join(df, df1.city == df.city, \"inner\").show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnXv002hok2z","executionInfo":{"status":"ok","timestamp":1686053808571,"user_tz":-330,"elapsed":1096,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"56d34732-3611-4996-a2c5-318e90f6d8cb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["+----+---+--------+-----+---+--------+\n","|name|age|    city| name|age|    city|\n","+----+---+--------+-----+---+--------+\n","|   A| 30|  London|Alice| 30|  London|\n","|   k| 25|New York| John| 25|New York|\n","|   B| 35|   Paris|  Bob| 35|   Paris|\n","+----+---+--------+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df1.union(df).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84zp99tmowdz","executionInfo":{"status":"ok","timestamp":1686053842701,"user_tz":-330,"elapsed":1482,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"2987ffb0-700a-4050-cdd7-77c2e058d866"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","|    k| 25|New York|\n","|    A| 30|  London|\n","|    B| 35|   Paris|\n","| John| 25|New York|\n","|Alice| 30|  London|\n","|  Bob| 35|   Paris|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df.drop(\"name\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouAIXcVmo85h","executionInfo":{"status":"ok","timestamp":1686053885089,"user_tz":-330,"elapsed":666,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"00380cdc-2a02-4ab6-ce53-aace71d8b396"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------+\n","|age|    city|\n","+---+--------+\n","| 25|New York|\n","| 30|  London|\n","| 35|   Paris|\n","+---+--------+\n","\n"]}]},{"cell_type":"code","source":["df.rdd.map(lambda x: x * 2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkuYxndrpI5_","executionInfo":{"status":"ok","timestamp":1686053936732,"user_tz":-330,"elapsed":3,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"d1a3aa2a-8023-4e1d-aa5d-65ff4927e25a"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[94] at RDD at PythonRDD.scala:53"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":[],"metadata":{"id":"o0wx0gIcpMz9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Actions pyspark\n","\n","In PySpark, actions are operations that trigger the execution of transformations and return results or perform some computation on a DataFrame or an RDD (Resilient Distributed Dataset). Unlike transformations, actions are eagerly executed and trigger the actual computation of the data."],"metadata":{"id":"hW1bglHFpkGb"}},{"cell_type":"code","source":["# show(): Displays the first few rows of a DataFrame\n","df.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gam6aLdwp2tK","executionInfo":{"status":"ok","timestamp":1686054091665,"user_tz":-330,"elapsed":677,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"2ecd31e7-a8d4-4e89-9f76-e4bae8fe2958"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+---+--------+\n","| name|age|    city|\n","+-----+---+--------+\n","| John| 25|New York|\n","|Alice| 30|  London|\n","|  Bob| 35|   Paris|\n","+-----+---+--------+\n","\n"]}]},{"cell_type":"code","source":["# count(): Returns the number of rows in a DataFrame.\n","df.count()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzusRmOxp7MD","executionInfo":{"status":"ok","timestamp":1686054119083,"user_tz":-330,"elapsed":728,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"0c349e32-dfc8-4f85-910a-9f0e935d46bb"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# collect(): Returns all the rows of a DataFrame as a list in the driver program.\n","\n","df.collect()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptneaVrQqB2q","executionInfo":{"status":"ok","timestamp":1686054143754,"user_tz":-330,"elapsed":720,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"feac609f-30b3-444c-c2fe-83f946dd163f"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(name='John', age=25, city='New York'),\n"," Row(name='Alice', age=30, city='London'),\n"," Row(name='Bob', age=35, city='Paris')]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["df.first() #first(): Returns the first row of a DataFrame.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cClRa_-qH5F","executionInfo":{"status":"ok","timestamp":1686054174988,"user_tz":-330,"elapsed":5,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"451bb45b-2c79-4620-92ce-c93e62ddd27f"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Row(name='John', age=25, city='New York')"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["#take(n): Returns the first n rows of a DataFrame as a list.\n","df.take(2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gDzi-70cqPs5","executionInfo":{"status":"ok","timestamp":1686054205267,"user_tz":-330,"elapsed":658,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"0103d74e-bcd4-4c70-f56e-62bacee1a521"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(name='John', age=25, city='New York'),\n"," Row(name='Alice', age=30, city='London')]"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["#reduce(): Applies a binary function to the elements of an RDD and returns the result.\n","rdd.reduce(lambda x, y: x + y)\n"],"metadata":{"id":"jciwbCXiqXCS","executionInfo":{"status":"ok","timestamp":1686054285456,"user_tz":-330,"elapsed":502,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["#foreach(): Applies a function to each element of an RDD\n","rdd.foreach(lambda x: print(x))\n"],"metadata":{"id":"5Lf6MFU-qmzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#saveAsTextFile(): Saves the contents of an RDD to a text file.\n","rdd.saveAsTextFile(\"output.txt\")\n"],"metadata":{"id":"tFRnsTzNqx4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pandas_df = df.toPandas()\n"],"metadata":{"id":"Qw6n4_PJq45N","executionInfo":{"status":"ok","timestamp":1686054361366,"user_tz":-330,"elapsed":785,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["pandas_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"dybVh_V3q8_e","executionInfo":{"status":"ok","timestamp":1686054374565,"user_tz":-330,"elapsed":5,"user":{"displayName":"vaibhav rokde","userId":"03224795862521431729"}},"outputId":"1edce247-6fb8-4811-f185-a10720b4f8fe"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    name  age      city\n","0   John   25  New York\n","1  Alice   30    London\n","2    Bob   35     Paris"],"text/html":["\n","  <div id=\"df-99c99c1d-0788-4eeb-babc-3624a5139803\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>age</th>\n","      <th>city</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>25</td>\n","      <td>New York</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Alice</td>\n","      <td>30</td>\n","      <td>London</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bob</td>\n","      <td>35</td>\n","      <td>Paris</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99c99c1d-0788-4eeb-babc-3624a5139803')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-99c99c1d-0788-4eeb-babc-3624a5139803 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-99c99c1d-0788-4eeb-babc-3624a5139803');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":[],"metadata":{"id":"vTg6jICmrAkU"},"execution_count":null,"outputs":[]}]}